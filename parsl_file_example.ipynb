{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro\n",
    "\n",
    "This notebook contains an example of using Parsl with a MapReduce like pattern using various types of data staging.\n",
    "\n",
    "It contains a bash_app that is run in parallel (16 times), with each instance staging in an input file over https and staging in a script over https.  It then runs the script on the input file, which creates an output file, specifically, it sharpens a jpeg image.  That output file is then staged by Globus to a public Globus endpoint (used for tutorials).\n",
    "\n",
    "Each task returns an AppFuture, and each AppFutures contains a DataFuture to one of the output files.\n",
    "\n",
    "The notebook then runs a python_app task that is dependent on all the DataFutures. This task build a mosaic assembled of parts of each of its input images, and that mosaic image is then staged back to the same Globus endpoint.\n",
    "\n",
    "Notes:\n",
    "1. The tasks are dependent on the Python library Pillow, which must be installed where the tasks are run.\n",
    "2. If the tasks are run in the same place, or with access to a shared file system, the final task shouldn't have to stage in the files from Globus, as they already exist locally where they were created by the first 16 tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Parsl\n",
    "Set up Parsl, and set up a config that uses threads, runs tasks in my laptop's Desktop directory, and has the globus endpoint associated with my laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import parsl\n",
    "import os\n",
    "\n",
    "print(parsl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parsl.config import Config\n",
    "from parsl.executors import ThreadPoolExecutor\n",
    "from parsl.data_provider.globus import GlobusStaging\n",
    "from parsl.data_provider.data_manager import default_staging\n",
    "\n",
    "config = Config(\n",
    "    executors=[\n",
    "        ThreadPoolExecutor(\n",
    "            working_dir=\"/Users/dsk/Desktop/parsl_tmp\",\n",
    "            storage_access=default_staging + [GlobusStaging(\n",
    "                endpoint_uuid=\"8ae0b9fe-9a00-11ea-8eca-02c81b96a709\",\n",
    "            )]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "parsl.load(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a task as a bash app that runs a script\n",
    "Define a Parsl bash app with three File parameters for the script, the input file, and the output file.\n",
    "\n",
    "`script` and `infile` are both File objects with the filepath attribute set to\n",
    "the execute side filepath, and with the content staged in before execution. The file will get staged in because it is a File object, not some other python object like `7` or a string.\n",
    "\n",
    "`outputs` is a list of File objects (with 1 entry when you call it because you only pass in one entry). The filepath attribute will be set to where you need to put the file on the execute-side filesystem in order for the staging out system to find it, to stage out afterwards.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parsl.app.app import python_app, bash_app\n",
    "from parsl.data_provider.files import File\n",
    "\n",
    "@bash_app\n",
    "def process_file(script, infile, outputs=[]):\n",
    "    return 'python3 {s} {i} {o}'.format(s=script.filepath, i=infile.filepath, o=outputs[0].filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a single task\n",
    "\n",
    "This is how to run a single task, but you can skip this and just go onto the following cell to run the set of 16 tasks in parallel - this cell is mostly for illustration.\n",
    "\n",
    "Define Parsl Files for the script to be run and the input file, both of which will be staged into the run location via https\n",
    "\n",
    "Also define the Parsl File for the output as a Globus file that will be staged via Globus.\n",
    "\n",
    "Then actually run the task, and block on the result.  (Note that this will return once the file is computed, but the staging may take more time to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script = File(\"https://github.com/danielskatz/parsl-example/raw/master/sharpen_image.py\")\n",
    "\n",
    "inputFile = File(\"https://github.com/danielskatz/parsl-example/raw/master/data/0001.jpg\")\n",
    "\n",
    "# This is an endpoint on my laptop, which fails because I don't a globus pro account\n",
    "# which would be needed to transfer between to globus connect endpoints.\n",
    "# If I was running on a cluster with a globus endpoint, I could use this.\n",
    "outputFile = File(\"globus://8ae0b9fe-9a00-11ea-8eca-02c81b96a709/Users/dsk/Globus_files/0001_sharp.jpg\")\n",
    "\n",
    "# This is a public endpoint used for globus tutorials, which is wiped every few weeks,\n",
    "# but can be used for temporary purposes.\n",
    "# You can view the contents via \n",
    "# https://app.globus.org/file-manager?origin_id=ddb59aef-6d04-11e5-ba46-22000b92c6ec&origin_path=%2F~%2F\n",
    "    \n",
    "outputFile = File(\"globus://ddb59aef-6d04-11e5-ba46-22000b92c6ec/~/0001_sharp.jpg\")\n",
    "\n",
    "output = process_file(script, inputFile, outputs=[outputFile])\n",
    "output.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a set of 16 tasks\n",
    "Define Parsl Files for the script to be run and the input files, both of which will be staged into the run location via https.\n",
    "\n",
    "Also define the Parsl Files for the outputs as Globus files that will be staged via Globus.\n",
    "\n",
    "Then actually run the tasks. (Note that this will return immediately, as the elements of the elements of `sharpImageFutures[]` are AppFutures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script = File(\"https://github.com/danielskatz/parsl-example/raw/master/sharpen_image.py\")\n",
    "\n",
    "sharpImageFutures = []\n",
    "\n",
    "for i in range(16):\n",
    "    inputFile = File(\"https://github.com/danielskatz/parsl-example/raw/master/data/{:04d}.jpg\".format(i+1))\n",
    "    outputFile = File(\"globus://ddb59aef-6d04-11e5-ba46-22000b92c6ec/~/{:04d}_sharp.jpg\".format(i+1))\n",
    "    sharpImageFutures.append(process_file(script, inputFile, outputs=[outputFile]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a python task to build a mosaic of parts of the 16 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@python_app\n",
    "def mosaic_files(inputs=[], outputs=[]):\n",
    "\n",
    "    try:\n",
    "        from PIL import Image, ImageFilter\n",
    "    except ImportError:\n",
    "        print(\"error:\", sys.argv[0], \"requires Pillow - install it via 'pip install Pillow'\")\n",
    "        sys.exit(2)\n",
    "\n",
    "    outputImage = Image.new('RGB', [400, 400])\n",
    "    index = 0\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            inputImage = Image.open(inputs[index].filepath)\n",
    "            box = ((i)*100, (j)*100, (i+1)*100, (j+1)*100)\n",
    "            region = inputImage.crop(box)\n",
    "            outputImage.paste(region, box)\n",
    "            index=index+1\n",
    "            \n",
    "    outputImage.save(outputs[0].filepath, 'JPEG')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the mosaic task\n",
    "Note that this task will run remotely, and is dependent on `sharpImageFutures`  The cell will block until the mosaic_files task has completed, but again, this doesn't mean that its output will have completed staging to the globus endpoint.\n",
    "\n",
    "Also note that this is not tremendously efficient with this resource configuration, the sharpened images are staged back from globus, even though they are already on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaicFile = File(\"globus://ddb59aef-6d04-11e5-ba46-22000b92c6ec/~/mosaic.jpg\")\n",
    "# Create a list of DataFutures from the AppFutures\n",
    "images = [out.outputs[0] for out in sharpImageFutures]\n",
    "\n",
    "mosaicFuture = mosaic_files(inputs=images,outputs=[mosaicFile])\n",
    "mosaicFuture.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now block on the stage out completing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaicFuture.outputs[0].result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
